\chapter{Stand der Technik}

\section{Hinderniserkennung}
Verschiedene Prinzipien stehen zur Bilderkennung zur Verfügung.
%Quellen nicht eindeutig
%Der Fokus dieses Projektes, das Erkennen und Ausweichen von Hindernissen wird \enquote{Obstacle Avoidance} genannt. Es ist nicht zu verwechseln mit \enquote{Obstacle Detection}, dem Erkennen und Klassifizieren von Bildinhalten.
Nachfolgend vorgestellt werden die grundlegenden Techniken der Bilderkennung. 
\subsubsection{SLAM Algorithmus}\label{chap:slam}
\Gls{slam} Techniken entstanden bereits in den 1980-1990 Jahren und werden bspw. bei Robotern eingesetzt, die in Hallen navigieren (für die kein \acrshort{gps} verfügbar ist). Zum Einsatz kommen Kamerasysteme in Verbindung mit Entfernungssensoren (Sonar, Radar, Lidar). Die Ergebnisse von \gls{slam} können nicht garantiert werden und sind nicht reproduzierbar, weshalb es in keinen kritischen Umgebungen (bspw. wenn Verletzungsrisiko besteht) eingesetzt werden kann.

Allgemein wird \gls{slam} durch einen modularen Prozess beschrieben:
\begin{description}
    \item[Lokalisierung:] per Motorfortschritt, \gls{imu}, Kamera, etc.%\newline Bei v\gls{slam} kommen folgende Prinzipien zum Einsatz:
    \item[Kartengenerierung:] durch einen der Algorithmen
\begin{itemize}
    \item Markov-Lokalisierung: Wahrscheinlichkeit des Aufenthaltsortes wird angenommen und über Zeit verfeinert; Iterativ; Ressourcenaufwendig
	\item Kalman-Filter: Ermöglicht basierend auf Sensordaten schnelles wiederfinden aktueller Position; anfällig bei Verlust von Eingangsdaten
	\item Monte-Carlo-Lokalisierung (Partikelfilter): nimmt Wahrscheinlichkeiten für jeden Ort an; genauer als Markov-Filter; lineare Komplexität; Weniger Speicher als Kalman-Filter; Nachteil: Stillstand ohne sich ändernde Sensordaten
\end{itemize}
    \item[Messung:] per Reichweite, Marker in Umgebung
\end{description}
%was sollte hier noch hin

\subsubsection{Visual SLAM} 
Eine Sonderform des \gls{slam} ist Visual \gls{slam} (vSLAM). Bei diesem werden ausschließlich Kameras zur Erkennung der Umgebung eingesetzt. Algorithmen verwenden zumeist zusätzlich die Daten der \acrshort{imu}, um die Bewegung der Kamera in die Berechnung der Position einzubeziehen.

\subsubsection{Stereokamera}\label{chap:stereovision}
Verwendet mehrere Kameras aus parallelverschobenen Bildern Tiefeninformationen zu gewinnen. also Abstand zu Punkten im Bild zu erkennen.
\subsubsection{Optical Flow}
In Bewegungsabläufen werden Objekten verfolgt und können somit relativ zur Kamera bestimmt werden. Das Prinzip wird auch von Lebewesen im Gehirn angewandt. Dabei kann schlecht zwischen der Bewegung der Kamera und der Bewegung von Objekten unterschieden werden. Ungenau, da Kameras immer eine Verzerrung besitzen. 

\section{Avoidance}
Das Projekt \enquote{Obstacle Detection and Avoidance}\cite{dronecodestiftungObstacleDetectionAvoidance2023}, auf GitHub verfügbar als PX4-Avoidance\footnote{\url{https://github.com/PX4/PX4-Avoidance}}, hier nur \textit{Avoidance} genannt, entstand in enger Zusammenarbeit mit der Dronecode Stiftung an der ETH Zürich.

Es stehen im Projekt 3 Algorithmen zur Verfügung, die unabhängig voneinander zu betrachten sind. Alle dienen der Anpassung der Flugbahn in unbekannter Umgebung:
\begin{description}
    \item[Local Planner:] Navigiert um Hindernisse in der direkten Umgebung
    \item[Global Planner:] Speichert nahezu vollständige Karte der Umgebung und erlaubt Navigation durch Labyrinth-artige Umgebung
    \item[Safe Landing Planner:]
\end{description}

Es arbeitet mit der Software des Flugcontrollers (PX4) und dem \acrshort{ros}-Metabetriebssystem. Die Software Avoidance erhält per \acrshort{ros}-Nachrichten die Soll-Trajektorie und Sensordaten vom Flugcontroller. Außerdem wird zur Navigation eine Punktwolke der Umgebung benötigt. Falls notwendig wird eine angepasste Trajektorie an den Flugcontroller gesendet.

Die Software kann nicht direkt auf dem Flugcontroller ausgeführt werden, da die Berechnungen sehr enorm viele Ressourcen benötigen. Weiterhin empfehlen die Entwickler, zuerst den Local Planner zu implementieren, da dieser am besten funktioniert. Offizielle Empfehlungen der Entwickler verwenden leisstungsstarke Hardware wie NVidia Jetson, Intel RealSense.

Sprich Stereokamera ist erprobt

Stereokamera liefert genaue Karte der Umgebung, ähnlich einem Lidar.

Andere Methoden arbeiten eventuell nicht mit Avoidance zusammen.
